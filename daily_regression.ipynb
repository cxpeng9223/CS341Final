{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shared/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFile(file_path):\n",
    "    file = pd.read_csv(file_path)\n",
    "    return file\n",
    "\n",
    "\n",
    "def train_test_split(mat):\n",
    "    train_mat = mat[0:2800, :]\n",
    "    test_mat = mat[2801:, :]\n",
    "\n",
    "    return train_mat, test_mat\n",
    "\n",
    "\n",
    "def train_test_split_lab(lab):\n",
    "    train_mat = lab[0:2800]\n",
    "    test_mat = lab[2801:]\n",
    "\n",
    "    return train_mat, test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_full_feature(mat, label1, label2):\n",
    "    # check if one data contains n/a feature, delte it and its correponding label\n",
    "    row_count = 0\n",
    "    full_list = []\n",
    "    for row in mat:\n",
    "        if np.any(np.isnan(row.astype(np.float64))):\n",
    "            pass\n",
    "        else:\n",
    "            full_list.append(row_count)\n",
    "\n",
    "        row_count += 1\n",
    "\n",
    "    mat = mat[full_list, :]\n",
    "    label1 = label1[full_list]\n",
    "    label2 = label2[full_list]\n",
    "\n",
    "    return mat, label1, label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(feature_mat, lab_mat):\n",
    "\n",
    "    model = linear_model.LinearRegression()\n",
    "    feature_mat = feature_mat.astype(np.float)\n",
    "    lab = lab_mat.astype(np.float)\n",
    "\n",
    "    print('Model training - Started!')\n",
    "    time_start = time.time()\n",
    "    model.fit(feature_mat, lab)\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('Model training - Completed! Training time: ' + str(time_end - time_start) + 's')\n",
    "\n",
    "    predicted_lab = model.predict(feature_mat)\n",
    "\n",
    "    return model, predicted_lab\n",
    "\n",
    "\n",
    "def linear_reg(X, y):\n",
    "    X_withIntercept = sm.add_constant(X)\n",
    "    model = sm.OLS(y.astype(float), X_withIntercept.astype(float))\n",
    "    est = model.fit()\n",
    "\n",
    "    return est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training - Started!\n",
      "Model training - Completed! Training time: 0.0020520687103271484s\n",
      "Model training - Started!\n",
      "Model training - Completed! Training time: 0.0029325485229492188s\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   R-squared:                       0.216\n",
      "Model:                            OLS   Adj. R-squared:                  0.215\n",
      "Method:                 Least Squares   F-statistic:                     128.6\n",
      "Date:                Fri, 20 Apr 2018   Prob (F-statistic):          5.39e-144\n",
      "Time:                        21:47:58   Log-Likelihood:                 5117.5\n",
      "No. Observations:                2800   AIC:                        -1.022e+04\n",
      "Df Residuals:                    2793   BIC:                        -1.018e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.2427      0.080      3.052      0.002       0.087       0.399\n",
      "state_of_econ        -0.2382      0.021    -11.223      0.000      -0.280      -0.197\n",
      "goodecon_now          0.3110      0.051      6.121      0.000       0.211       0.411\n",
      "lifeladder_now        0.0432      0.006      7.072      0.000       0.031       0.055\n",
      "lifeladder_future    -0.0291      0.007     -4.426      0.000      -0.042      -0.016\n",
      "future_of_econ        0.2161      0.063      3.439      0.001       0.093       0.339\n",
      "goodecon_future      -0.2530      0.126     -2.004      0.045      -0.501      -0.005\n",
      "==============================================================================\n",
      "Omnibus:                      315.776   Durbin-Watson:                   0.583\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              445.258\n",
      "Skew:                           0.867   Prob(JB):                     2.06e-97\n",
      "Kurtosis:                       3.901   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      0   R-squared:                       0.267\n",
      "Model:                            OLS   Adj. R-squared:                  0.265\n",
      "Method:                 Least Squares   F-statistic:                     169.3\n",
      "Date:                Fri, 20 Apr 2018   Prob (F-statistic):          4.70e-184\n",
      "Time:                        21:47:58   Log-Likelihood:                 5252.7\n",
      "No. Observations:                2800   AIC:                        -1.049e+04\n",
      "Df Residuals:                    2793   BIC:                        -1.045e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "const                 0.5332      0.076      7.035      0.000       0.385       0.682\n",
      "state_of_econ        -0.2464      0.020    -12.183      0.000      -0.286      -0.207\n",
      "goodecon_now          0.1887      0.048      3.898      0.000       0.094       0.284\n",
      "lifeladder_now        0.0307      0.006      5.280      0.000       0.019       0.042\n",
      "lifeladder_future    -0.0241      0.006     -3.842      0.000      -0.036      -0.012\n",
      "future_of_econ        0.1864      0.060      3.112      0.002       0.069       0.304\n",
      "goodecon_future      -0.2510      0.120     -2.086      0.037      -0.487      -0.015\n",
      "==============================================================================\n",
      "Omnibus:                      415.832   Durbin-Watson:                   0.587\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              652.509\n",
      "Skew:                           1.025   Prob(JB):                    2.04e-142\n",
      "Kurtosis:                       4.180   Cond. No.                     2.27e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.27e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    cal_rate_df = parseFile('CleanedData/daily_unemployment.csv')\n",
    "    cal_rate = np.array(cal_rate_df)[:, 1] # unemployment rate from our caculation\n",
    "\n",
    "    gallup_data_df = parseFile('CleanedData/gallup_daily.csv')\n",
    "    gallup_rate = 1 - np.array(gallup_data_df)[:, 2] # unemployment rate from gallup_daily.csv\n",
    "\n",
    "    header_list = list(gallup_data_df.columns.values) #feautres' names\n",
    "\n",
    "    senti_features = np.array(gallup_data_df)[:, 3:9] # sentiment features array (3000,7)\n",
    "\n",
    "    senti_features, gallup_rate, cal_rate = filter_full_feature(senti_features, gallup_rate, cal_rate)\n",
    "\n",
    "    # split train test data\n",
    "    cal_rate_train, cal_rate_test = train_test_split_lab(cal_rate) \n",
    "    gallup_rate_train, gallup_rate_test = train_test_split_lab(gallup_rate)\n",
    "    sent_train, sent_test = train_test_split(senti_features)\n",
    "\n",
    "    # train\n",
    "    model_cal, cal_pred = model_train(sent_train, cal_rate_train)\n",
    "    model_gallup, gallup_pred = model_train(sent_train, gallup_rate_train)\n",
    "\n",
    "\n",
    "    senti_features_df = pd.DataFrame(sent_train, columns= header_list[3:9])\n",
    "    cal_label = pd.DataFrame(cal_rate_train)\n",
    "    model_cal_reg = linear_reg(senti_features_df, cal_label)\n",
    "    print(model_cal_reg.summary())\n",
    "\n",
    "\n",
    "    gallup_label = pd.DataFrame(gallup_rate_train)\n",
    "    model_gallup_reg = linear_reg(senti_features_df, gallup_label)\n",
    "    print(model_gallup_reg.summary())\n",
    "\n",
    "    rate_pred = model_cal.predict(senti_features)\n",
    "\n",
    "    plt.plot(cal_rate, label= 'calculated_rate')\n",
    "    plt.plot(rate_pred, label='predicted_rate')\n",
    "    plt.legend()\n",
    "    plt.savefig('cal_rate_compare.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    rate_pred = model_gallup.predict(senti_features)\n",
    "\n",
    "\n",
    "    plt.plot(gallup_rate, label= 'calculated_rate')\n",
    "    plt.plot(rate_pred, label='predicted_rate')\n",
    "    plt.legend()\n",
    "    plt.savefig('gallup_rate_compare.png')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
