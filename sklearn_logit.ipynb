{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the data file to memeory.\n",
    "\n",
    "#Input: File path to read.\n",
    "#Output: A 2d numpy array with all loaded samples from the file to read in string.\n",
    "\n",
    "def parseFile(file):\n",
    "    time_start = time.time()\n",
    "\n",
    "    content = []\n",
    "    count, count_incomplete,count_complete, count_part = 0, 0, 0, 0\n",
    "\n",
    "    with open(file) as txtfile:\n",
    "        for row in txtfile:\n",
    "\n",
    "            row = row.split(',')\n",
    "            row[-1] = row[-1].strip()\n",
    "\n",
    "            content.append(row)\n",
    "\n",
    "            count += 1\n",
    "\n",
    "    content_mat = np.array(content)\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('Reading data is complete! Running time is ' + str(time_end - time_start) + 's!')\n",
    "\n",
    "    return content_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to filter the samples with no missing values. \n",
    "#Input: mat - 2d Numpy Array.\n",
    "#Onput: mat - 2d Numpy Array with all samples that have no Missing values.\n",
    "\n",
    "def filter_full_feature(mat):\n",
    "    row_count = 0\n",
    "    full_list = []\n",
    "    for row in mat:\n",
    "        if 'N/A' in row or 'NA' in row:\n",
    "            pass\n",
    "        else:\n",
    "            full_list.append(row_count)\n",
    "\n",
    "        row_count += 1\n",
    "    print('There are a total of ' + str(len(full_list)) + ' samples fed into the model')\n",
    "    mat = mat[full_list, :]\n",
    "    return mat\n",
    "\n",
    "#Function to split up the full dataset into a training and testing set in 80:20 ratio.\n",
    "#Input: mat - A 2d Numpy array\n",
    "#Output: train_mat, test_mat - 2 deperate Numpy arrays each as a subset of the full mat set, \n",
    "#        with a rough ratio of 80:20\n",
    "\n",
    "def train_test_split(mat):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    num_sample, num_var = mat.shape\n",
    "\n",
    "    for i in range(0, num_sample):\n",
    "        if i == 0:\n",
    "            train_list.append(i)\n",
    "            test_list.append(i)\n",
    "        else:\n",
    "            rand = random.random()\n",
    "            if rand >= 0.2:\n",
    "                train_list.append(i)\n",
    "            else:\n",
    "                test_list.append(i)\n",
    "\n",
    "    train_mat = mat[train_list, :]\n",
    "    test_mat = mat[test_list, :]\n",
    "\n",
    "    return train_mat, test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(mat, label_location):\n",
    "    #model = linear_model.LogisticRegression()\n",
    "    num_sam, num_var = mat.shape\n",
    "    model = ensemble.RandomForestClassifier(n_estimators = 15,min_samples_split= 30, min_samples_leaf = 18)\n",
    "    feature_mat = np.delete(mat, label_location, axis=1)[1:, :].astype(np.float)\n",
    "    feature_mat = np.concatenate((feature_mat, (feature_mat[:, 9] * feature_mat[:, 9]).reshape((num_sam-1, 1))), axis=1)\n",
    "    labels = mat[1:, label_location].astype(np.int)\n",
    "    print('Model training - Started!')\n",
    "    time_start = time.time()\n",
    "    model.fit(feature_mat, labels)\n",
    "    time_end = time.time()\n",
    "    print('Model training - Completed! Training time: ' + str(time_end - time_start) + 's')\n",
    "\n",
    "    predicted_lab = model.predict(feature_mat)\n",
    "    corrected_pred = np.sum(labels == predicted_lab)\n",
    "\n",
    "    training_error = 1 - corrected_pred/labels.size\n",
    "\n",
    "    return model, training_error\n",
    "\n",
    "\n",
    "def model_test(model, mat, label_location):\n",
    "    num_sam, num_var = mat.shape\n",
    "    feature_mat = np.delete(mat, label_location, axis=1)[1:, :].astype(np.float)\n",
    "    feature_mat = np.concatenate((feature_mat, (feature_mat[:, 9] * feature_mat[:, 9]).reshape((num_sam-1, 1))), axis=1)\n",
    "    labels = mat[1:, label_location].astype(np.int)\n",
    "\n",
    "    predicted_lab = model.predict(feature_mat)\n",
    "    corrected_pred = np.sum(labels == predicted_lab)\n",
    "    \n",
    "    label_score = model.predict_proba(feature_mat)\n",
    "    \n",
    "    print(roc_auc_score(labels, label_score[:, 1]))\n",
    "    \n",
    "    np.savetxt('predicted_lab_RF.txt', predicted_lab.astype(np.int))\n",
    "    np.savetxt('label_test_RF.txt', labels.astype(np.int))\n",
    "\n",
    "    test_error = 1 - corrected_pred / labels.size\n",
    "    return test_error\n",
    "\n",
    "def model_sim(model, mat):\n",
    "    feature_mat = mat.astype(np.float)\n",
    "    num_sim, num_var = feature_mat.shape\n",
    "    feature_mat = np.concatenate((feature_mat, (feature_mat[:, 9] * feature_mat[:, 9]).reshape((num_sim, 1))), axis=1)\n",
    "    predicted_lab = model.predict(feature_mat).reshape(num_sim, 1)\n",
    "    \n",
    "    full_mat = np.concatenate((feature_mat, predicted_lab), axis=1)\n",
    "    \n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data is complete! Running time is 64.16577959060669s!\n",
      "Reading data is complete! Running time is 0.2495899200439453s!\n",
      "There are a total of 1010924 samples fed into the model\n",
      "Model training - Started!\n",
      "Model training - Completed! Training time: 40.87759041786194s\n",
      "0.8118732270275417\n",
      "The training error for this trail is: 0.2245326513348932\n",
      "The testing error for this trail is: 0.25046584848679565\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    content_mat = parseFile('CleanedData/gallup_clean_NA_No_D_coor.txt')\n",
    "    #content_mat = parseFile('CleanedData/gallup_clean_NA_determinant.txt')\n",
    "    #content_mat = parseFile('CleanedData/gallup_mean_filled_cleaned.txt')\n",
    "    \n",
    "    sim_mat = parseFile('sim_out.txt')\n",
    "    \n",
    "    num_sample, num_var = content_mat.shape\n",
    "    \n",
    "    #sentiment_list = [0, 1, 2, 3, 21, 22, 32] #sentiment & label(21)\n",
    "\n",
    "    sentiment_list = [0, 1, 2, 3, 21, 22, 32, 29, 6, 47, 48, num_var -2,  num_var-1] #sentiment & background & label(21)\n",
    "    new_sen_list = np.sort(sentiment_list)\n",
    "    sentiment_idx_list = np.searchsorted(new_sen_list, sentiment_list)\n",
    "    \n",
    "    full_list = list(range(0, num_var))\n",
    "    delete_list = list(set(full_list) - set(sentiment_list))\n",
    "\n",
    "    content_mat = np.delete(content_mat, delete_list, axis=1)\n",
    "        \n",
    "    content_mat = content_mat[:-200000, :]\n",
    "    \n",
    "    content_mat = filter_full_feature(content_mat)\n",
    "    content_mat = content_mat[:, sentiment_idx_list]\n",
    "    \n",
    "    content_mat = np.concatenate((content_mat[:, 0:7] , content_mat[:, -2:num_var + 1] , content_mat[:, 7:11]), axis=1)\n",
    "    #content_mat = np.concatenate((content_mat, content_mat[:, 10].astype(np.int) * content_mat[:, 10].astype(np.int)), axis=1)\n",
    "    \n",
    "    train_mat, test_mat = train_test_split(content_mat)\n",
    "\n",
    "    model, train_error = model_train(train_mat, 4)\n",
    "\n",
    "    test_error = model_test(model, test_mat, 4)\n",
    "    \n",
    "    sim_result = model_sim(model, sim_mat)\n",
    "\n",
    "    print('The training error for this trail is: ' + str(train_error))\n",
    "    print('The testing error for this trail is: ' + str(test_error))\n",
    "    \n",
    "    np.savetxt('sim_result.txt', sim_result)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
