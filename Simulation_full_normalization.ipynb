{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import linear_model\n",
    "from sklearn import ensemble\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the data file to memeory.\n",
    "\n",
    "#Input: File path to read.\n",
    "#Output: A 2d numpy array with all loaded samples from the file to read in string.\n",
    "\n",
    "def parseFile_raw(file):\n",
    "    time_start = time.time()\n",
    "\n",
    "    content = []\n",
    "    count, count_incomplete,count_complete, count_part = 0, 0, 0, 0\n",
    "    \n",
    "    with open(file) as txtfile:\n",
    "        for row in txtfile:\n",
    "            \n",
    "            row = row.split(',')\n",
    "            row[-1] = row[-1].strip()\n",
    "            #if count != 0:\n",
    "            content.append([row[21]] + row[0:4] + [row[22]] + [row[32]] + [row[29]] + [row[6]] \\\n",
    "                           + [row[-2]] + [row[-1]] + [row[12].strip(\"'\")])\n",
    "\n",
    "            count += 1\n",
    "            #if count == 1000:\n",
    "                #break\n",
    "\n",
    "    content_mat = np.array(content)\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('Reading data is complete! Running time is ' + str(time_end - time_start) + 's!')\n",
    "\n",
    "    return content_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load the data file to memeory, this is for the simulation hash data.\n",
    "\n",
    "#Input: File path to read.\n",
    "#Output: A 2d numpy array with all loaded samples from the file to read in string.\n",
    "\n",
    "def parseFile_reference(file):\n",
    "    time_start = time.time()\n",
    "\n",
    "    content = []\n",
    "    count, count_incomplete,count_complete, count_part = 0, 0, 0, 0\n",
    "    \n",
    "    with open(file) as txtfile:\n",
    "        for row in txtfile:\n",
    "            row = row.split(',')\n",
    "            row[-1] = row[-1].strip().strip(']').strip('\\n')\n",
    "            row[0] = row[0][1:]\n",
    "            row[0] = row[0].strip(\"'\")\n",
    "    \n",
    "            content.append(row)\n",
    "\n",
    "    reference_mat = np.array(content)\n",
    "\n",
    "    time_end = time.time()\n",
    "    print('Reading data is complete! Running time is ' + str(time_end - time_start) + 's!')\n",
    "\n",
    "    return reference_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFile_indi(file):\n",
    "\n",
    "    with open(file, 'r') as csvfile:\n",
    "        indi_list = []\n",
    "        for line in csvfile:\n",
    "            indi_list.append(line.strip().replace('-', ' ').split(','))\n",
    "\n",
    "    indicator_array = np.array(indi_list)\n",
    "    \n",
    "    return indicator_array[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to filter the samples with no missing values. \n",
    "#Input: mat - 2d Numpy Array.\n",
    "#Onput: mat - 2d Numpy Array with all samples that have no Missing values.\n",
    "\n",
    "def filter_full_feature(mat):\n",
    "    row_count = 0\n",
    "    full_list = []\n",
    "    for row in mat:\n",
    "        if 'N/A' in row or 'NA' in row:\n",
    "            pass\n",
    "        else:\n",
    "            full_list.append(row_count)\n",
    "\n",
    "        row_count += 1\n",
    "    print('There are a total of ' + str(len(full_list)) + ' samples fed into the model')\n",
    "    mat = mat[full_list, :]\n",
    "    return mat\n",
    "\n",
    "#Function to split the fullset into training and test sets.\n",
    "#Input: mat - 2d Numpy Array.\n",
    "#Onput: train_mat: 2d Numpy Array, test_mat: 2d Numpy Array\n",
    "def train_test_split(mat):\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    num_sample, num_var = mat.shape\n",
    "\n",
    "    for i in range(0, num_sample):\n",
    "        if i == 0:\n",
    "            train_list.append(i)\n",
    "            test_list.append(i)\n",
    "        else:\n",
    "            rand = random.random()\n",
    "            if rand >= 0.2:\n",
    "                train_list.append(i)\n",
    "            else:\n",
    "                test_list.append(i)\n",
    "\n",
    "    train_mat = mat[train_list, :]\n",
    "    test_mat = mat[test_list, :]\n",
    "\n",
    "    return train_mat, test_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a probability into the coordinate of a zip code using population probability distritbuion\n",
    "#prob: float between 0 and 1\n",
    "#reference_array: a 2-d array contaning the coordinates of the reference zipcodes\n",
    "#prob_dist: a 1-d array shows the accumulated population distribution as a percentage of the total population in the US.\n",
    "def getzip(prob, reference_array, prob_dist):\n",
    "    idx = np.where(prob_dist >= prob)\n",
    "    idx = idx[0][0]\n",
    "    coord = reference_array[idx, :]\n",
    "    \n",
    "    return coord, idx\n",
    "\n",
    "#convert the index and probability from getzip() and get the gender of the simulation from a gender reference\n",
    "#idx: the index returned from getzip()\n",
    "#gender_ref: a 2-d Array that contains the gender distribution of each zip code.\n",
    "# 1-male, 0-female.\n",
    "def getgender(idx, gender_ref):\n",
    "    prob = random.random()\n",
    "    \n",
    "    if prob >= gender_ref[idx]:\n",
    "        gender = 0\n",
    "    else:\n",
    "        gender = 1\n",
    "    \n",
    "    return gender\n",
    "\n",
    "#convert the index, gender and a probability from getzip() and get the age of the simulation from an age reference\n",
    "def getage(idx, age_ref, gender):\n",
    "    age_ref_male = age_ref[:, :18]\n",
    "    age_ref_female = age_ref[:, 18:]\n",
    "    prob = random.random()\n",
    "    \n",
    "    if gender == 1:\n",
    "        idx_age = np.where(age_ref_male[idx] >= prob)\n",
    "        if idx_age[0].size != 0:\n",
    "            idx_age = idx_age[0][0]\n",
    "            delta = random.randint(0, 4)\n",
    "        \n",
    "            age = idx_age * 5 + delta\n",
    "        else:\n",
    "            age = 90\n",
    "    else:\n",
    "        idx_age = np.where(age_ref_female[idx] >= prob)\n",
    "        if idx_age[0].size != 0:\n",
    "            idx_age = idx_age[0][0]\n",
    "            delta = random.randint(0, 4)\n",
    "        \n",
    "            age = idx_age * 5 + delta\n",
    "        else:\n",
    "            age = 90\n",
    "\n",
    "    return age\n",
    "\n",
    "#convert the index and a probability from getzip() and get the race of the simulation from a race reference\n",
    "def getrace(idx, race_ref):\n",
    "    prob = random.random()\n",
    "    idx_race = np.where(race_ref[idx] >= prob)\n",
    "    idx_race = idx_race[0][0]\n",
    "    \n",
    "    return idx_race + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert a zip code to its coresponding coordinate.\n",
    "#zip_array: a 1-d array that is a list of zip_code\n",
    "#reference_array: a 2-d array contaning the coordinates of the reference zipcodes\n",
    "def zip_to_coordinate(zip_array, reference_array):\n",
    "    count = 0\n",
    "    coordinate_list = []\n",
    "    full_list = []\n",
    "    zip_ref = reference_array[:, 0].astype(np.int)\n",
    "    for zip_c in zip_array:\n",
    "        idx = np.argwhere(zip_ref == int(zip_c))\n",
    "        if idx.size != 0:\n",
    "            coordinate_pair = reference_array[idx[0][0], 1:3]\n",
    "            full_list.append(count)\n",
    "        else: #there are some zipcodes were P.O box addresses and not in our reference. So we look for the nearby zipcodes\n",
    "            zip_c_back = int(zip_c) - 1\n",
    "            zip_c_forward = int(zip_c) + 1\n",
    "            idx_back = np.argwhere(zip_ref == zip_c_back)\n",
    "            idx_forward = np.argwhere(zip_ref == zip_c_forward)\n",
    "            if idx_back.size != 0:\n",
    "                coordinate_pair = reference_array[idx_back[0][0], 1:3]\n",
    "                full_list.append(count)\n",
    "            elif idx_forward.size != 0:\n",
    "                coordinate_pair = reference_array[idx_forward[0][0], 1:3]\n",
    "                full_list.append(count)\n",
    "            else:\n",
    "                coordinate_pair = ['N/A', 'N/A']\n",
    "                \n",
    "        count += 1\n",
    "        coordinate_list.append(coordinate_pair)\n",
    "    return np.array(coordinate_list), full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_knn(coordinate_array, gender_array, age_array, race_array, prob_dist, daily_indicator):\n",
    "    \n",
    "    # generate a random probability prop to population distri. (use zip for now)\n",
    "    prob = random.random() # 0.0~1.0\n",
    "    \n",
    "    #longi, lati = getcoord(zip)\n",
    "    coordinate, idx = getzip(prob, coordinate_array, prob_dist)\n",
    "    \n",
    "    gender = getgender(idx, gender_array)\n",
    "    \n",
    "    x_knn = np.append(coordinate, gender)\n",
    "    \n",
    "    age = getage(idx, age_array, gender)\n",
    "    \n",
    "    x_knn = np.append(x_knn, age)\n",
    "    \n",
    "    race = getrace(idx, race_array)\n",
    "    \n",
    "    x_knn = np.append(x_knn, race)\n",
    "    \n",
    "    x_knn = np.append(x_knn, daily_indicator)\n",
    "\n",
    "    # generate sentiment features (use knn for now)\n",
    "    #senti_feature = neigh_model.predict([x_knn])\n",
    "    \n",
    "    return x_knn\n",
    "\n",
    "def simulation(neigh_model, x_knn):\n",
    "    \n",
    "    senti_feature = neigh_model.predict(x_knn)\n",
    "    return senti_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(mat, label_location):\n",
    "    model = linear_model.LogisticRegression()\n",
    "    num_sam, num_var = mat.shape\n",
    "    #model = ensemble.RandomForestClassifier(n_estimators = 15,min_samples_split= 30, min_samples_leaf = 18)\n",
    "    feature_mat = np.delete(mat, label_location, axis=1).astype(np.float)\n",
    "    feature_mat = np.concatenate((feature_mat, (feature_mat[:, 9] * feature_mat[:, 9]).reshape((num_sam, 1))), axis=1)\n",
    "    labels = mat[:, label_location].astype(np.int)\n",
    "    print('Model training - Started!')\n",
    "    time_start = time.time()\n",
    "    model.fit(feature_mat, labels)\n",
    "    time_end = time.time()\n",
    "    print('Model training - Completed! Training time: ' + str(time_end - time_start) + 's')\n",
    "\n",
    "    predicted_lab = model.predict(feature_mat)\n",
    "    corrected_pred = np.sum(labels == predicted_lab)\n",
    "\n",
    "    training_error = 1 - corrected_pred/labels.size\n",
    "\n",
    "    return model, training_error\n",
    "\n",
    "\n",
    "def model_test(model, mat, label_location):\n",
    "    num_sam, num_var = mat.shape\n",
    "    feature_mat = np.delete(mat, label_location, axis=1).astype(np.float)\n",
    "    feature_mat = np.concatenate((feature_mat, (feature_mat[:, 9] * feature_mat[:, 9]).reshape((num_sam, 1))), axis=1)\n",
    "    labels = mat[:, label_location].astype(np.int)\n",
    "\n",
    "    predicted_lab = model.predict(feature_mat)\n",
    "    corrected_pred = np.sum(labels == predicted_lab)\n",
    "    \n",
    "    label_score = model.predict_proba(feature_mat)\n",
    "    \n",
    "    print('The current model stands an AUC of ' + str(roc_auc_score(labels, label_score[:, 1])))\n",
    "    \n",
    "    np.savetxt('predicted_lab_RF.txt', predicted_lab.astype(np.int))\n",
    "    np.savetxt('label_test_RF.txt', labels.astype(np.int))\n",
    "\n",
    "    test_error = 1 - corrected_pred / labels.size\n",
    "    return test_error\n",
    "\n",
    "def model_sim(model, mat):\n",
    "    feature_mat = mat.astype(np.float)\n",
    "    num_sim, num_var = feature_mat.shape\n",
    "    feature_mat = np.concatenate((feature_mat, (feature_mat[:, 9] * feature_mat[:, 9]).reshape((num_sim, 1))), axis=1)\n",
    "    predicted_lab = model.predict(feature_mat).reshape(num_sim, 1)\n",
    "    \n",
    "    full_mat = np.concatenate((feature_mat, predicted_lab), axis=1)\n",
    "    \n",
    "    return full_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data is complete! Running time is 29.653443336486816s!\n",
      "There are a total of 1029512 samples fed into the model\n",
      "Reading data is complete! Running time is 0.3556091785430908s!\n",
      "There are a total of 32800 samples fed into the model\n",
      "Reading data is complete! Running time is 0.07932257652282715s!\n",
      "There are a total of 32800 samples fed into the model\n",
      "Model training - Started!\n",
      "Model training - Completed! Training time: 14.218538999557495s\n",
      "The current model stands an AUC of 0.7934299344924831\n",
      "The training error for this trail is: 0.25859212143887966\n",
      "The testing error for this trail is: 0.2593084392284748\n",
      "Started simulation cycle 0\n",
      "[[  34.346938  -83.895627    0.         64.          1.         24.09    ]\n",
      " [  41.011602  -73.841433    0.         62.          1.         24.09    ]\n",
      " [  46.275451  -96.089793    1.         70.          1.         24.09    ]\n",
      " [  45.509203 -122.433468    1.         11.          1.         24.09    ]\n",
      " [  38.49206   -90.3863      1.         47.          1.         24.09    ]\n",
      " [  39.131717  -89.481382    1.         47.          1.         24.09    ]\n",
      " [  40.512662  -78.373929    1.         32.          4.         24.09    ]\n",
      " [  34.964267  -92.063652    1.         26.          1.         24.09    ]\n",
      " [  46.875879 -114.233416    1.         13.          1.         24.09    ]\n",
      " [  29.952629  -95.446609    0.         39.          1.         24.09    ]]\n",
      "[[ 0.0008807  -0.00088652]\n",
      " [ 0.00105159 -0.00078028]\n",
      " [ 0.00118657 -0.00101538]\n",
      " [ 0.00116692 -0.00129375]\n",
      " [ 0.00098699 -0.00095511]\n",
      " [ 0.00100339 -0.00094554]\n",
      " [ 0.0010388  -0.00082817]\n",
      " [ 0.00089653 -0.00097283]\n",
      " [ 0.00120196 -0.0012071 ]\n",
      " [ 0.00076803 -0.00100858]]\n"
     ]
    },
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-77aead9509c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-77aead9509c6>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalized_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0moutput_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_classify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0msim_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    file = \"CleanedData/gallup_clean_NA_determinant.txt\"\n",
    "    file_age = \"CleanedData/ppl_by_zip.txt\"\n",
    "    file_race = \"CleanedData/race_by_zip.txt\"\n",
    "    \n",
    "    file_indi = \"CleanedData/daily_ind_1.csv\"\n",
    "    \n",
    "    simu_iter = 15        #327500000 is current US population\n",
    "    \n",
    "    raw_data = parseFile_raw(file) #raw_data from Gallup daily survey\n",
    "    header = raw_data[0,:]\n",
    "    cleaned_data_input = filter_full_feature(raw_data)[1:,:]  #cleaned_data input from Gallup\n",
    "    \n",
    "    label = cleaned_data_input[:, :1] #employmed label\n",
    "    cleaned_data = cleaned_data_input[:, 1:]\n",
    "    \n",
    "    age_data = parseFile_reference(file_age)\n",
    "    age_data = filter_full_feature(age_data)[1:,:]\n",
    "    coordinate = age_data[:,2:4].astype(np.float) # (longi,lati)\n",
    "    index = age_data[:,-1].astype(np.float) # prob\n",
    "    age_dist = age_data[:, 5:-2].astype(np.float)\n",
    "    \n",
    "    race_data = parseFile_reference(file_race)\n",
    "    race_data = filter_full_feature(race_data)[1:,:]\n",
    "    race_dist = race_data[:, 2:].astype(np.float)\n",
    "    \n",
    "    zipcode = age_data[:,:1]\n",
    "    gender_distribution = age_data[:, 4:5].astype(np.float)\n",
    "    \n",
    "    combined_zip_ref = np.concatenate((zipcode, coordinate), axis=1)\n",
    "    \n",
    "    zip_code_ind = cleaned_data[:, 10] \n",
    "    ind_coordinate, full_list = zip_to_coordinate(zip_code_ind, combined_zip_ref) # coreponding coordinate of the samples.\n",
    "    \n",
    "    content_mat = np.concatenate((cleaned_data,ind_coordinate),axis=1)\n",
    "    content_mat = content_mat[full_list, :]\n",
    "    label = label[full_list, :]\n",
    "    \n",
    "    num_sam, num_var = content_mat.shape\n",
    "    \n",
    "    X_knn = content_mat[:, -2:num_var + 1].astype(np.float)# zip vec\n",
    "    gender = content_mat[:, 6].astype(np.int)\n",
    "    age = content_mat[:, 7].astype(np.int)\n",
    "    race = content_mat[:, -5].astype(np.int)\n",
    "    daily_ind =  content_mat[:, -4].astype(np.float)\n",
    "    X_knn = np.concatenate((X_knn, gender.reshape((num_sam, 1)), age.reshape((num_sam, 1)), race.reshape((num_sam, 1)),daily_ind.reshape((num_sam, 1)) ),axis=1)\n",
    "    y_knn = content_mat[:,:6].astype(np.int) # senti mat\n",
    "    \n",
    "    sim_prob_ref = age_data[:, -1].astype(np.float)\n",
    "    \n",
    "    '''\n",
    "    time_knn = time.time()\n",
    "    neigh = KNeighborsClassifier(n_neighbors=10, weights= 'distance')\n",
    "    neigh.fit(X_knn, y_knn)\n",
    "    time_knn_end = time.time()\n",
    "    print('KNN takes ' + str(time_knn_end - time_knn) + 's')\n",
    "    '''\n",
    "    \n",
    "    content_mat = np.concatenate((label, y_knn, X_knn), axis=1)\n",
    "    train_mat, test_mat = train_test_split(content_mat)\n",
    "    \n",
    "    model, train_error = model_train(train_mat, 0)\n",
    "    test_error = model_test(model, test_mat, 0)\n",
    "    \n",
    "    print('The training error for this trail is: ' + str(train_error))\n",
    "    print('The testing error for this trail is: ' + str(test_error))\n",
    "    \n",
    "    ind_list = parseFile_indi(file_indi).astype(np.float)\n",
    "    #num_sim = ind_list.shape\n",
    "    \n",
    "    employment_rate_18 = []\n",
    "    employment_rate_25_54 = []\n",
    "    \n",
    "    #employment_rate_18.append('>18')\n",
    "    #employment_rate_25_54.append('25 - 54')\n",
    "    count = 0\n",
    "    for ind in ind_list:\n",
    "        time_start = time.time()\n",
    "        print('Started simulation cycle ' + str(count))\n",
    "        \n",
    "        X_classify = []\n",
    "        coord_list = []\n",
    "        for i in range(simu_iter):\n",
    "            coord = get_X_knn(coordinate, gender_distribution, age_dist, race_dist, sim_prob_ref, ind)\n",
    "            coord_list.append(coord)\n",
    "            #X_classify.append(senti_fea[0])\n",
    "          \n",
    "    # throw simulated data into the model, predict their unemplotment rate\n",
    "        #X_classify = np.array(X_classify)\n",
    "        coord_list = np.array(coord_list)\n",
    "        full_x_list = np.concatenate((coord_list, X_knn), axis = 0)\n",
    "        \n",
    "        print(full_x_list[0:10, :])\n",
    "        \n",
    "        scaler = preprocessing.MinMaxScaler()\n",
    "        scaler.fit()\n",
    "        normalized_list = preprocessing.normalize(full_x_list[:, 0:2], axis = 0, norm ='l2')\n",
    "        \n",
    "        print(normalized_list[0:10,:])\n",
    "        \n",
    "        output_array = np.concatenate((X_classify, coord_list), axis=1)\n",
    "        \n",
    "        sim_result = model_sim(model, output_array)\n",
    "        \n",
    "        age_array = sim_result[:, 9].reshape((simu_iter, 1))\n",
    "        employment_array = sim_result[:, -1].reshape((simu_iter, 1))\n",
    "        \n",
    "        over_18_list = np.argwhere(age_array >= 18)\n",
    "        age_25_54_list = np.argwhere((age_array >= 25) & (age_array <= 54))\n",
    "        #over_18_population = over_18_list.shape\n",
    "        num_over_18, dim = over_18_list.shape\n",
    "        num_25_54, dim = age_25_54_list.shape\n",
    "        \n",
    "        employment_array_18 = employment_array[over_18_list[:,0]]\n",
    "        employment_array_25_54 = employment_array[age_25_54_list[:,0]]\n",
    "        \n",
    "        employment_rate_18.append(np.sum(employment_array_18)/num_over_18)\n",
    "        employment_rate_25_54.append(np.sum(employment_array_25_54)/num_25_54)\n",
    "        time_end = time.time()\n",
    "        print('Simulation Cycle ' + str(count) + ' finished in ' + str(time_end - time_start) + 's!')\n",
    "        count += 1\n",
    "        \n",
    "        #if count == 10:\n",
    "            #break\n",
    "        \n",
    "    age_18 = np.array(employment_rate_18).reshape((count, 1))\n",
    "    age_25_54 = np.array(employment_rate_25_54).reshape((count, 1))\n",
    "    \n",
    "    #ind_list_out = ind_list.reshape(num_sim, 1)\n",
    "    \n",
    "    output_array = np.concatenate((age_18, age_25_54), axis=1)\n",
    "    np.savetxt('sim_out_daily_test.txt', output_array, delimiter=',', fmt='%1.4f,%1.4f')\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
